{"cells":[{"cell_type":"code","execution_count":1,"id":"ad8fd3c6","metadata":{"id":"ad8fd3c6","executionInfo":{"status":"ok","timestamp":1744445024369,"user_tz":-60,"elapsed":14220,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from torch.utils.data import DataLoader\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":2,"id":"62b6df1b","metadata":{"id":"62b6df1b","executionInfo":{"status":"ok","timestamp":1744445024395,"user_tz":-60,"elapsed":20,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["def generate_classification_synthetic_data(num_samples=100_000, num_features=20, seed=42):\n","    torch.manual_seed(seed)\n","    X = torch.randn(num_samples, num_features)\n","\n","    weights = torch.randn(num_features)\n","    bias = torch.randn(1)\n","    logits = X @ weights + bias\n","    probabilities = torch.sigmoid(logits)\n","\n","    y = (probabilities > 0.5).float().unsqueeze(1)\n","    return X, y\n","\n","\n","def generate_synthetic_regression_data(num_samples=100_000, num_features=20, seed=42):\n","    torch.manual_seed(seed)\n","    X = torch.randn(num_samples, num_features)\n","\n","    weights = torch.randn(num_features)\n","    bias = torch.randn(1)\n","\n","    linear_part = X @ weights + bias\n","    nonlinear_part = torch.sin(X[:, 0]) + torch.log(torch.abs(X[:, 1]) + 1) + 0.5 * X[:, 2] ** 2\n","\n","    y = linear_part + nonlinear_part + 0.1 * torch.randn(num_samples)\n","    y = y.unsqueeze(1)\n","\n","    return X, y\n"]},{"cell_type":"code","execution_count":3,"id":"9c14c607","metadata":{"id":"9c14c607","executionInfo":{"status":"ok","timestamp":1744445024453,"user_tz":-60,"elapsed":54,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["X, y = generate_synthetic_regression_data()\n","\n","dataset = TensorDataset(X, y)\n","batch_size=64\n","val_split=0.2\n","\n","val_size = int(len(dataset) * val_split)\n","train_size = len(dataset) - val_size\n","train_ds, val_ds = random_split(dataset, [train_size, val_size])"]},{"cell_type":"code","execution_count":4,"id":"72a88001","metadata":{"id":"72a88001","executionInfo":{"status":"ok","timestamp":1744445024596,"user_tz":-60,"elapsed":137,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":5,"id":"e70d8800","metadata":{"id":"e70d8800","executionInfo":{"status":"ok","timestamp":1744445028338,"user_tz":-60,"elapsed":3722,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["class HousingModel(nn.Module):\n","    def __init__(self, num_cols, hidden_size):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(num_cols, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n","        self.output = nn.Linear(hidden_size // 2, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        # x = torch.sigmoid(self.output(x)) # classification\n","        x = self.output(x) # regression\n","        return x\n","\n","\n","model = HousingModel(\n","    num_cols=X.shape[1],\n","    hidden_size=20\n",").to(device)\n","\n","lr = 1e-3\n","loss_fn = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","id":"5bfddf71","metadata":{"id":"5bfddf71"},"source":["- optimizer.zero_grad() clear old gradients\n","- loss.backward() compute gradients from loss\n","- torch.nn.utils.clip_grad_norm_(...) stabilize with gradient clipping\n","- optimizer.step() update parameters using gradients"]},{"cell_type":"code","execution_count":6,"id":"d050fba8","metadata":{"id":"d050fba8","executionInfo":{"status":"ok","timestamp":1744445028349,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[],"source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","  size = len(dataloader.dataset)\n","  loss_history = []\n","  score_history = []\n","\n","  for batch, (X, y) in enumerate(dataloader):\n","    # compute prediction and loss\n","    pred = model(X).squeeze(1) # forward pass\n","    loss = loss_fn(pred, y.squeeze(1))\n","\n","    # backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n","    optimizer.step()\n","\n","    if batch % 1000 == 0:\n","      loss, current = loss.item(), batch * len(X)\n","      loss_history.append(loss)\n","\n","      score = mean_squared_error(y.cpu().detach().numpy().tolist(), pred.cpu().detach().numpy().tolist())\n","      score_history.append(score)\n","\n","      print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n","\n","  return loss_history, score_history\n","\n","\n","def predict(dataloader, model):\n","  final_preds = []\n","\n","  model.eval()\n","  with torch.no_grad():\n","    for X, _ in dataloader:\n","      pred = model(X).squeeze(1)\n","      final_preds.extend(pred.cpu().detach().numpy().tolist())\n","\n","  return final_preds"]},{"cell_type":"code","execution_count":7,"id":"369c6fff","metadata":{"id":"369c6fff","outputId":"a09b6072-98b1-4a0a-8f70-d5dfef7a8cc8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744445035279,"user_tz":-60,"elapsed":6927,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 16.605732  [    0/80000]\n","loss: 0.131220  [64000/80000]\n","Epoch 2\n","-------------------------------\n","loss: 0.184492  [    0/80000]\n","loss: 0.110185  [64000/80000]\n","Epoch 3\n","-------------------------------\n","loss: 0.194690  [    0/80000]\n","loss: 0.193746  [64000/80000]\n"]}],"source":["loss_history = []\n","score_history = []\n","\n","epochs = 3\n","\n","for epoch in range(epochs):\n","   print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n","   epoch_loss_history, epoch_score_history = train_loop(train_dataloader, model, loss_fn, optimizer)\n","   loss_history.extend(epoch_loss_history)\n","   score_history.extend(epoch_score_history)"]},{"cell_type":"code","execution_count":8,"id":"57f16f15","metadata":{"id":"57f16f15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744445035581,"user_tz":-60,"elapsed":266,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}},"outputId":"e77d8699-e489-4352-a420-7f849d64b269"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.12335046865072342"]},"metadata":{},"execution_count":8}],"source":["y_test = []\n","for batch in val_ds:\n","    _, y = batch\n","    y_test.append(y.item())\n","\n","\n","y_pred = predict(test_dataloader, model)\n","mean_squared_error(y_test, y_pred)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}