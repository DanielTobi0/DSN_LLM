{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmpuCkfnhi8/HcvgshOq0O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## POS Tagging\n","\n","Part-of-Speech (POS) tagging is a natural language processing technique that involves assigning specific grammatical categories or labels (such as nouns, verbs, adjectives, adverbs, pronouns, etc.) to individual words within a sentence."],"metadata":{"id":"GGoWb5RpcQhj"}},{"cell_type":"code","source":["import nltk\n","nltk.download('treebank')\n","from nltk.corpus import treebank\n","import random\n","\n","# Load the tagged sentences from the treebank\n","tagged_sents = list(treebank.tagged_sents())\n","\n","# Shuffle and split the data: 90% for training, 10% for testing\n","random.shuffle(tagged_sents)\n","split_index = int(0.9 * len(tagged_sents))\n","train_data = tagged_sents[:split_index]\n","test_data = tagged_sents[split_index:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSg60v5j3QZv","executionInfo":{"status":"ok","timestamp":1743761741326,"user_tz":-60,"elapsed":13306,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}},"outputId":"2507d9eb-600f-4a3d-e204-cfdeafe5d6cc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n"]}]},{"cell_type":"code","source":["import math\n","from collections import defaultdict, Counter\n","\n","class HMMPOSTagger:\n","    def __init__(self):\n","        # Count dictionaries to collect statistics from the training data\n","        self.initial_counts = Counter()\n","        self.transition_counts = defaultdict(Counter)\n","        self.emission_counts = defaultdict(Counter)\n","        self.tag_counts = Counter()\n","        self.vocab = set()\n","        self.tags = set()\n","\n","    def train(self, tagged_sentences):\n","        \"\"\"\n","        Trains the HMM POS tagger on a list of sentences.\n","        Each sentence is a list of (word, tag) pairs.\n","        \"\"\"\n","        for sentence in tagged_sentences:\n","            if not sentence:\n","                continue\n","            # Update count for the first tag in each sentence\n","            first_word, first_tag = sentence[0]\n","            self.initial_counts[first_tag] += 1\n","\n","            for i, (word, tag) in enumerate(sentence):\n","                self.tag_counts[tag] += 1\n","                self.emission_counts[tag][word] += 1\n","                self.vocab.add(word)\n","                self.tags.add(tag)\n","                # For transitions, consider the previous tag (if any)\n","                if i > 0:\n","                    prev_tag = sentence[i-1][1]\n","                    self.transition_counts[prev_tag][tag] += 1\n","\n","        self.total_sentences = len(tagged_sentences)\n","\n","        # Compute initial probabilities with add-one smoothing\n","        self.initial_probs = {}\n","        for tag in self.tags:\n","            self.initial_probs[tag] = math.log((self.initial_counts[tag] + 1) / (self.total_sentences + len(self.tags)))\n","\n","        # Compute transition probabilities with add-one smoothing\n","        self.transition_probs = {}\n","        for prev_tag in self.tags:\n","            self.transition_probs[prev_tag] = {}\n","            total_transitions = sum(self.transition_counts[prev_tag].values())\n","            for curr_tag in self.tags:\n","                self.transition_probs[prev_tag][curr_tag] = math.log(\n","                    (self.transition_counts[prev_tag][curr_tag] + 1) /\n","                    (total_transitions + len(self.tags))\n","                )\n","\n","        # Compute emission probabilities with add-one smoothing\n","        self.emission_probs = {}\n","        for tag in self.tags:\n","            self.emission_probs[tag] = {}\n","            total_emissions = sum(self.emission_counts[tag].values())\n","            for word in self.vocab:\n","                self.emission_probs[tag][word] = math.log(\n","                    (self.emission_counts[tag][word] + 1) /\n","                    (total_emissions + len(self.vocab))\n","                )\n","            # For words not seen during training, assign a small probability.\n","            self.emission_probs[tag]['<UNK>'] = math.log(1 / (total_emissions + len(self.vocab)))\n","\n","    def viterbi(self, sentence):\n","        \"\"\"\n","        Uses the Viterbi algorithm to decode the best tag sequence for a given sentence.\n","        sentence: list of words.\n","        Returns: list of predicted tags.\n","        \"\"\"\n","        n = len(sentence)\n","        if n == 0:\n","            return []\n","\n","        # delta holds the best scores for each tag at each word position.\n","        delta = [{} for _ in range(n)]\n","        # backpointer holds the best previous tag that led to the current tag.\n","        backpointer = [{} for _ in range(n)]\n","\n","        # Initialization for the first word\n","        for tag in self.tags:\n","            word = sentence[0] if sentence[0] in self.vocab else '<UNK>'\n","            delta[0][tag] = self.initial_probs.get(tag, float('-inf')) + \\\n","                            self.emission_probs[tag].get(word, self.emission_probs[tag]['<UNK>'])\n","            backpointer[0][tag] = None\n","\n","        # Recursion through the sentence\n","        for t in range(1, n):\n","            for curr_tag in self.tags:\n","                word = sentence[t] if sentence[t] in self.vocab else '<UNK>'\n","                best_prev_tag = None\n","                best_score = float('-inf')\n","                for prev_tag in self.tags:\n","                    score = delta[t-1][prev_tag] + \\\n","                            self.transition_probs[prev_tag].get(curr_tag, float('-inf')) + \\\n","                            self.emission_probs[curr_tag].get(word, self.emission_probs[curr_tag]['<UNK>'])\n","                    if score > best_score:\n","                        best_score = score\n","                        best_prev_tag = prev_tag\n","                delta[t][curr_tag] = best_score\n","                backpointer[t][curr_tag] = best_prev_tag\n","\n","        # Backtrack to find the best tag sequence\n","        best_final_tag = max(delta[n-1], key=delta[n-1].get)\n","        best_path = [best_final_tag]\n","        for t in range(n-1, 0, -1):\n","            best_path.insert(0, backpointer[t][best_path[0]])\n","\n","        return best_path"],"metadata":{"id":"SMQMZ7eG3RGE","executionInfo":{"status":"ok","timestamp":1743761741419,"user_tz":-60,"elapsed":89,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["tagger = HMMPOSTagger()\n","print(\"Training on {} sentences...\".format(len(train_data)))\n","tagger.train(train_data)\n","\n","# Evaluate on the test set\n","correct = 0\n","total = 0\n","for sentence in test_data:\n","    words = [word for word, tag in sentence]\n","    gold_tags = [tag for word, tag in sentence]\n","    predicted_tags = tagger.viterbi(words)\n","    total += len(gold_tags)\n","    correct += sum(1 for pt, gt in zip(predicted_tags, gold_tags) if pt == gt)\n","\n","accuracy = correct / total\n","print(\"Accuracy on test set: {:.2%}\".format(accuracy))\n","\n","# Tag a sample sentence\n","sample_sentence = \"The quick brown fox jumps over the lazy dog\".split()\n","predicted_sample_tags = tagger.viterbi(sample_sentence)\n","print(\"Sample sentence:\", sample_sentence)\n","print(\"Predicted tags:\", predicted_sample_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brOPqbRg3T4A","executionInfo":{"status":"ok","timestamp":1743761756235,"user_tz":-60,"elapsed":14793,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}},"outputId":"c42719f6-4590-4bd3-f19f-7a1f24691dc3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on 3522 sentences...\n","Accuracy on test set: 85.65%\n","Sample sentence: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n","Predicted tags: ['DT', 'JJ', 'NN', '.', \"''\", 'IN', 'DT', 'NN', 'IN']\n"]}]},{"cell_type":"code","source":["# https://www.kaggle.com/code/nilaychauhan/part-of-speech-tagging-with-hidden-markov-models"],"metadata":{"id":"qZzpeJ7L3Xqd","executionInfo":{"status":"ok","timestamp":1743761973083,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel Tobi","userId":"10779748150936298898"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NtmqNxScUB33"},"execution_count":null,"outputs":[]}]}