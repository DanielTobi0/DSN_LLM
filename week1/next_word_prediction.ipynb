{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIR5m0Xmn_y-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 53671,
     "status": "error",
     "timestamp": 1743515544763,
     "user": {
      "displayName": "Daniel Tobi",
      "userId": "10779748150936298898"
     },
     "user_tz": -60
    },
    "id": "9kNBtsU_j-0C",
    "outputId": "d98645fe-c48c-4d71-b9c9-d835fc77a56e"
   },
   "outputs": [],
   "source": [
    "class HMMNextWordPredictor:\n",
    "    def __init__(self):\n",
    "        self.corpus = nltk.corpus.brown.sents(categories=['news'])\n",
    "        self.pos_transitions = defaultdict(Counter)\n",
    "        self.pos_emissions = defaultdict(Counter)\n",
    "        self.pos_sequence_to_next_words = defaultdict(Counter)\n",
    "\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        \"\"\"Train the HMM model on the corpus.\"\"\"\n",
    "        print(\"Training the model...\")\n",
    "\n",
    "        for sentence in self.corpus:\n",
    "            if len(sentence) < 3:\n",
    "                continue\n",
    "\n",
    "            tagged_sentence = pos_tag(sentence)\n",
    "\n",
    "            for i in range(len(tagged_sentence) - 1):\n",
    "                current_word, current_pos = tagged_sentence[i]\n",
    "                next_word, next_pos = tagged_sentence[i + 1]\n",
    "\n",
    "                current_word = current_word.lower()\n",
    "                next_word = next_word.lower()\n",
    "\n",
    "                self.pos_transitions[current_pos][next_pos] += 1\n",
    "                self.pos_emissions[current_pos][current_word] += 1\n",
    "\n",
    "                if i > 0:\n",
    "                    prev_word, prev_pos = tagged_sentence[i-1]\n",
    "                    pos_sequence = (prev_pos, current_pos)\n",
    "                    self.pos_sequence_to_next_words[pos_sequence][next_word] += 1\n",
    "\n",
    "        self._normalize_probabilities()\n",
    "\n",
    "        print(\"Model training complete!\")\n",
    "\n",
    "    def _normalize_probabilities(self):\n",
    "        \"\"\"Convert frequency counts to probability distributions.\"\"\"\n",
    "        for pos, transitions in self.pos_transitions.items():\n",
    "            total = sum(transitions.values())\n",
    "            for next_pos in transitions:\n",
    "                transitions[next_pos] /= total\n",
    "\n",
    "        for pos, emissions in self.pos_emissions.items():\n",
    "            total = sum(emissions.values())\n",
    "            for word in emissions:\n",
    "                emissions[word] /= total\n",
    "\n",
    "        # Normalize POS sequence to next word probabilities\n",
    "        for pos_seq, next_words in self.pos_sequence_to_next_words.items():\n",
    "            total = sum(next_words.values())\n",
    "            for word in next_words:\n",
    "                next_words[word] /= total\n",
    "\n",
    "    def predict_next_word(self, text, n=5):\n",
    "        \"\"\"\n",
    "        Predict the most likely next words given the input text.\n",
    "\n",
    "        Args:\n",
    "            text (str): Input text\n",
    "            n (int): Number of predictions to return\n",
    "\n",
    "        Returns:\n",
    "            list: Top n predicted words with their probabilities\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(text)\n",
    "        if len(tokens) < 2:\n",
    "            return [(\"Need at least 2 words for prediction\", 0)]\n",
    "\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "        last_pos = tagged_tokens[-1][1]\n",
    "        second_last_pos = tagged_tokens[-2][1] if len(tagged_tokens) > 1 else None\n",
    "        pos_sequence = (second_last_pos, last_pos)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        if pos_sequence in self.pos_sequence_to_next_words:\n",
    "            candidate_words = self.pos_sequence_to_next_words[pos_sequence]\n",
    "            predictions.extend([(word, prob) for word, prob in candidate_words.most_common(n)])\n",
    "\n",
    "        if not predictions or len(predictions) < n:\n",
    "            next_pos_probs = self.pos_transitions[last_pos]\n",
    "\n",
    "            for next_pos, trans_prob in next_pos_probs.items():\n",
    "                for word, emit_prob in self.pos_emissions[next_pos].items():\n",
    "                    joint_prob = trans_prob * emit_prob\n",
    "                    predictions.append((word, joint_prob))\n",
    "\n",
    "            predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "        return predictions[:n]\n",
    "\n",
    "    def interactive_prediction(self):\n",
    "        \"\"\"Interactive console for next word prediction.\"\"\"\n",
    "        print(\"Welcome to HMM-based Next Word Prediction!\")\n",
    "        print(\"Type a sentence and get predictions for the next word.\")\n",
    "        print(\"Type 'exit' to quit.\")\n",
    "\n",
    "        while True:\n",
    "            text = input(\"\\nEnter text: \")\n",
    "            if text.lower() == 'exit':\n",
    "                break\n",
    "\n",
    "            predictions = self.predict_next_word(text)\n",
    "\n",
    "            print(\"\\nPredicted next words:\")\n",
    "            for i, (word, prob) in enumerate(predictions, 1):\n",
    "                print(f\"{i}. {word} (probability: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6MlIOS8kWhE"
   },
   "outputs": [],
   "source": [
    "predictor = HMMNextWordPredictor()\n",
    "\n",
    "test_text = \"The president of the\"\n",
    "predictions = predictor.predict_next_word(test_text)\n",
    "\n",
    "print(f\"\\nInput: '{test_text}'\")\n",
    "print(\"Predicted next words:\")\n",
    "for word, prob in predictions:\n",
    "    print(f\"- {word} (probability: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.interactive_prediction()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNcsmtLPdGFCizRGJY5Y8uS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
